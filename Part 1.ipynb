{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Stable-Baselines3` Tutorial - Part 1\n",
    "Created by following [this](https://pythonprogramming.net/introduction-reinforcement-learning-stable-baselines-3-tutorial/) tutorial by sentdex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3 import A2C, PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample action: 3\n",
      "observation space shape: (8,)\n",
      "sample observation: [-0.11661723  0.2551806  -0.5293492   0.43286434 -0.43185088  0.7570258\n",
      "  0.84934956  0.2473871 ]\n"
     ]
    }
   ],
   "source": [
    "# Making the environment\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "# Inspecting the environment\n",
    "print('sample action:', env.action_space.sample())\n",
    "print('observation space shape:', env.observation_space.shape)\n",
    "print('sample observation:', env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the environment\n",
    "env.reset()\n",
    "for step in range(200):\n",
    "\tenv.render()\n",
    "\tenv.step(env.action_space.sample()) # take random action\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2C Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 116      |\n",
      "|    ep_rew_mean        | -387     |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | -0.0115  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.956   |\n",
      "|    value_loss         | 5.81     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 125      |\n",
      "|    ep_rew_mean        | -282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.256    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 2.85     |\n",
      "|    value_loss         | 37.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 128      |\n",
      "|    ep_rew_mean        | -254     |\n",
      "| time/                 |          |\n",
      "|    fps                | 151      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.23    |\n",
      "|    explained_variance | -0.00345 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -3.3     |\n",
      "|    value_loss         | 7.49     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 141      |\n",
      "|    ep_rew_mean        | -232     |\n",
      "| time/                 |          |\n",
      "|    fps                | 170      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.895   |\n",
      "|    explained_variance | 0.000162 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.606   |\n",
      "|    value_loss         | 0.574    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 152       |\n",
      "|    ep_rew_mean        | -243      |\n",
      "| time/                 |           |\n",
      "|    fps                | 183       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.15     |\n",
      "|    explained_variance | -0.000472 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -2.64     |\n",
      "|    value_loss         | 39.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 155      |\n",
      "|    ep_rew_mean        | -233     |\n",
      "| time/                 |          |\n",
      "|    fps                | 194      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | -0.00489 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -1.39    |\n",
      "|    value_loss         | 3.83     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 162      |\n",
      "|    ep_rew_mean        | -225     |\n",
      "| time/                 |          |\n",
      "|    fps                | 204      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.87    |\n",
      "|    explained_variance | -0.00184 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 3.49     |\n",
      "|    value_loss         | 39.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 165      |\n",
      "|    ep_rew_mean        | -211     |\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.805   |\n",
      "|    explained_variance | -0.00877 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    value_loss         | 4.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 166      |\n",
      "|    ep_rew_mean        | -194     |\n",
      "| time/                 |          |\n",
      "|    fps                | 207      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.483   |\n",
      "|    explained_variance | -0.00165 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.554    |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 170      |\n",
      "|    ep_rew_mean        | -189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 212      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.637   |\n",
      "|    explained_variance | -0.105   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 12.1     |\n",
      "|    value_loss         | 299      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 175      |\n",
      "|    ep_rew_mean        | -182     |\n",
      "| time/                 |          |\n",
      "|    fps                | 214      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.716   |\n",
      "|    explained_variance | 0.0129   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.952   |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 181      |\n",
      "|    ep_rew_mean        | -176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.27    |\n",
      "|    explained_variance | 2.01e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -5.84    |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 183      |\n",
      "|    ep_rew_mean        | -173     |\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.689   |\n",
      "|    explained_variance | 0.000304 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 3.93     |\n",
      "|    value_loss         | 73       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | -169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.518   |\n",
      "|    explained_variance | -0.123   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 3.21     |\n",
      "|    value_loss         | 289      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.0873   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 11.6     |\n",
      "|    value_loss         | 114      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 184      |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.871   |\n",
      "|    explained_variance | -0.136   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.0499   |\n",
      "|    value_loss         | 0.0123   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 206      |\n",
      "|    ep_rew_mean        | -159     |\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.726   |\n",
      "|    explained_variance | 0.0336   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.815    |\n",
      "|    value_loss         | 5.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 209      |\n",
      "|    ep_rew_mean        | -156     |\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.621   |\n",
      "|    explained_variance | 0.00939  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 209      |\n",
      "|    ep_rew_mean        | -158     |\n",
      "| time/                 |          |\n",
      "|    fps                | 224      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | -0.219   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -3.65    |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 206      |\n",
      "|    ep_rew_mean        | -155     |\n",
      "| time/                 |          |\n",
      "|    fps                | 226      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.783   |\n",
      "|    explained_variance | 0.00625  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.669    |\n",
      "|    value_loss         | 1.9      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x1fdfb563a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and training an A2C model\n",
    "a2c_model = A2C('MlpPolicy', env, verbose=1)\n",
    "a2c_model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing model performance\n",
    "episodes = 5\n",
    "for ep in range(episodes):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\twhile not done:\n",
    "\t\taction, _states = a2c_model.predict(obs) # pass observation to model to get predicted action\n",
    "\t\tobs, reward, done, info = env.step(action) # pass action to env and get info back\n",
    "\t\tenv.render() # show the environment on the screen\n",
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 91.9     |\n",
      "|    ep_rew_mean     | -175     |\n",
      "| time/              |          |\n",
      "|    fps             | 448      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 93.1        |\n",
      "|    ep_rew_mean          | -174        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011935966 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.000844   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 534         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.6         |\n",
      "|    ep_rew_mean          | -166         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053341826 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.0236      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 1.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94          |\n",
      "|    ep_rew_mean          | -160        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013531888 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.0757     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 518         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 936         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.9        |\n",
      "|    ep_rew_mean          | -163        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013097205 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0545     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    value_loss           | 604         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1fd90793b20>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and training a PPO model\n",
    "ppo_model = PPO('MlpPolicy', env, verbose=1)\n",
    "ppo_model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing model performance\n",
    "episodes = 5\n",
    "for ep in range(episodes):\n",
    "\tobs = env.reset()\n",
    "\tdone = False\n",
    "\twhile not done:\n",
    "\t\taction, _states = ppo_model.predict(obs) # pass observation to model to get predicted action\n",
    "\t\tobs, reward, done, info = env.step(action) # pass action to env and get info back\n",
    "\t\tenv.render() # show the environment on the screen\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6869a3fcd5fc665c02cfd6671afb83b30427e0c0f4ed20c6135df23c280a7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
